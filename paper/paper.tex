%%
%% Beginning of file 'sample62.tex'
%%
%% Modified 2018 January
%%
%% This is a sample manuscript marked up using the
%% AASTeX v6.2 LaTeX 2e macros.
%%
%% AASTeX is now based on Alexey Vikhlinin's emulateapj.cls 
%% (Copyright 2000-2015).  See the classfile for details.

%% AASTeX requires revtex4-1.cls (http://publish.aps.org/revtex4/) and
%% other external packages (latexsym, graphicx, amssymb, longtable, and epsf).
%% All of these external packages should already be present in the modern TeX 
%% distributions.  If not they can also be obtained at www.ctan.org.

%% The first piece of markup in an AASTeX v6.x document is the \documentclass
%% command. LaTeX will ignore any data that comes before this command. The 
%% documentclass can take an optional argument to modify the output style.
%% The command below calls the preprint style  which will produce a tightly 
%% typeset, one-column, single-spaced document.  It is the default and thus
%% does not need to be explicitly stated.
%%
%%
%% using aastex version 6.2
\documentclass[preprint2]{aastex62}

\usepackage{url}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{natbib}
\usepackage{multirow}
\bibliographystyle{aasjournal}


%% The default is a single spaced, 10 point font, single spaced article.
%% There are 5 other style options available via an optional argument. They
%% can be envoked like this:
%%
%% \documentclass[argument]{aastex62}
%% 
%% where the layout options are:
%%
%%  twocolumn   : two text columns, 10 point font, single spaced article.
%%                This is the most compact and represent the final published
%%                derived PDF copy of the accepted manuscript from the publisher
%%  manuscript  : one text column, 12 point font, double spaced article.
%%  preprint    : one text column, 12 point font, single spaced article.  
%%  preprint2   : two text columns, 12 point font, single spaced article.
%%  modern      : a stylish, single text column, 12 point font, article with
%% 		  wider left and right margins. This uses the Daniel
%% 		  Foreman-Mackey and David Hogg design.
%%  RNAAS       : Preferred style for Research Notes which are by design 
%%                lacking an abstract and brief. DO NOT use \begin{abstract}
%%                and \end{abstract} with this style.
%%
%% Note that you can submit to the AAS Journals in any of these 6 styles.
%%
%% There are other optional arguments one can envoke to allow other stylistic
%% actions. The available options are:
%%
%%  astrosymb    : Loads Astrosymb font and define \astrocommands. 
%%  tighten      : Makes baselineskip slightly smaller, only works with 
%%                 the twocolumn substyle.
%%  times        : uses times font instead of the default
%%  linenumbers  : turn on lineno package.
%%  trackchanges : required to see the revision mark up and print its output
%%  longauthor   : Do not use the more compressed footnote style (default) for 
%%                 the author/collaboration/affiliations. Instead print all
%%                 affiliation information after each name. Creates a much
%%                 long author list but may be desirable for short author papers
%%
%% these can be used in any combination, e.g.
%%
%% \documentclass[twocolumn,linenumbers,trackchanges]{aastex62}
%%
%% AASTeX v6.* now includes \hyperref support. While we have built in specific
%% defaults into the classfile you can manually override them with the
%% \hypersetup command. For example,
%%
%%\hypersetup{linkcolor=red,citecolor=green,filecolor=cyan,urlcolor=magenta}
%%
%% will change the color of the internal links to red, the links to the
%% bibliography to green, the file links to cyan, and the external links to
%% magenta. Additional information on \hyperref options can be found here:
%% https://www.tug.org/applications/hyperref/manual.html#x1-40003
%%
%% If you want to create your own macros, you can do so
%% using \newcommand. Your macros should appear before
%% the \begin{document} command.
%%

% todos
\newcommand{\todo}[3]{{\color{#2}\emph{#1}: #3}}
\newcommand{\agoltodo}[1]{\todo{Agol}{blue}{#1}}
\newcommand{\gordontodo}[1]{\todo{Gordon}{red}{#1}}

% projects
\newcommand{\project}[1]{\textsf{#1}}
\newcommand{\celerite}{\project{celerite }}

% useful commands
\newcommand{\bvec}[1]{{\ensuremath{\boldsymbol{#1}}}}
\newcommand{\T}{\ensuremath{\mathrm{T}}}
\newcommand{\expandvec}[2]{\left(\begin{array}{ccccc} #1\quad && \cdots\quad && #2 \end{array}\right)}

%% Tells LaTeX to search for image files in the 
%% current directory as well as in the figures/ folder.
\graphicspath{}

%% Reintroduced the \received and \accepted commands from AASTeX v5.2
\received{}
\revised{}
\accepted{}
%% Command to document which AAS Journal the manuscript was submitted to.
%% Adds "Submitted to " the arguement.
\submitjournal{}

%% Mark up commands to limit the number of authors on the front page.
%% Note that in AASTeX v6.2 a \collaboration call (see below) counts as
%% an author in this case.
%
%\AuthorCollaborationLimit=3
%
%% Will only show Schwarz, Muench and "the AAS Journals Data Scientist 
%% collaboration" on the front page of this example manuscript.
%%
%% Note that all of the author will be shown in the published article.
%% This feature is meant to be used prior to acceptance to make the
%% front end of a long author article more manageable. Please do not use
%% this functionality for manuscripts with less than 20 authors. Conversely,
%% please do use this when the number of authors exceeds 40.
%%
%% Use \allauthors at the manuscript end to show the full author list.
%% This command should only be used with \AuthorCollaborationLimit is used.

%% The following command can be used to set the latex table counters.  It
%% is needed in this document because it uses a mix of latex tabular and
%% AASTeX deluxetables.  In general it should not be needed.
%\setcounter{table}{1}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%
%% The following section outlines numerous optional output that
%% can be displayed in the front matter or as running meta-data.
%%
%% If you wish, you may supply running head information, although
%% this information may be modified by the editorial offices.
\shorttitle{Celerite2D}
\shortauthors{Gordon et al.}
%%
%% You can add a light gray and diagonal water-mark to the first page 
%% with this command:
% \watermark{text}
%% where "text", e.g. DRAFT, is the text to appear.  If the text is 
%% long you can control the water-mark size with:
%  \setwatermarkfontsize{dimension}
%% where dimension is any recognized LaTeX dimension, e.g. pt, in, etc.
%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%% This is the end of the preamble.  Indicate the beginning of the
%% manuscript itself with \begin{document}.

\begin{document}

\title{}

%% LaTeX will automatically break titles if they run longer than
%% one line. However, you may use \\ to force a line break if
%% you desire. In v6.2 you can include a footnote in the title.

%% A significant change from earlier AASTEX versions is in the structure for 
%% calling author and affilations. The change was necessary to implement 
%% autoindexing of affilations which prior was a manual process that could 
%% easily be tedious in large author manuscripts.
%%
%% The \author command is the same as before except it now takes an optional
%% arguement which is the 16 digit ORCID. The syntax is:
%% \author[xxxx-xxxx-xxxx-xxxx]{Author Name}
%%
%% This will hyperlink the author name to the author's ORCID page. Note that
%% during compilation, LaTeX will do some limited checking of the format of
%% the ID to make sure it is valid.
%%
%% Use \affiliation for affiliation information. The old \affil is now aliased
%% to \affiliation. AASTeX v6.2 will automatically index these in the header.
%% When a duplicate is found its index will be the same as its previous entry.
%%
%% Note that \altaffilmark and \altaffiltext have been removed and thus 
%% can not be used to document secondary affiliations. If they are used latex
%% will issue a specific error message and quit. Please use multiple 
%% \affiliation calls for to document more than one affiliation.
%%
%% The new \altaffiliation can be used to indicate some secondary information
%% such as fellowships. This command produces a non-numeric footnote that is
%% set away from the numeric \affiliation footnotes.  NOTE that if an
%% \altaffiliation command is used it must come BEFORE the \affiliation call,
%% right after the \author command, in order to place the footnotes in
%% the proper location.
%%
%% Use \email to set provide email addresses. Each \email will appear on its
%% own line so you can put multiple email address in one \email call. A new
%% \correspondingauthor command is available in V6.2 to identify the
%% corresponding author of the manuscript. It is the author's responsibility
%% to make sure this name is also in the author list.
%%
%% While authors can be grouped inside the same \author and \affiliation
%% commands it is better to have a single author for each. This allows for
%% one to exploit all the new benefits and should make book-keeping easier.
%%
%% If done correctly the peer review system will be able to
%% automatically put the author and affiliation information from the manuscript
%% and save the corresponding author the trouble of entering it by hand.

\correspondingauthor{Tyler A. Gordon}
\email{tagordon@uw.edu}

\author{Tyler A. Gordon}
\affiliation{Department of Astronomy, University of Washington, Box 351580, U.W., Seattle, WA 98195-1580, USA}

\author{Eric Agol}
\affiliation{Department of Astronomy, University of Washington, Box 351580, U.W., Seattle, WA 98195-1580, USA}

%% Note that the \and command from previous versions of AASTeX is now
%% depreciated in this version as it is no longer necessary. AASTeX 
%% automatically takes care of all commas and "and"s between authors names.

%% AASTeX 6.2 has the new \collaboration and \nocollaboration commands to
%% provide the collaboration status of a group of authors. These commands 
%% can be used either before or after the list of corresponding authors. The
%% argument for \collaboration is the collaboration identifier. Authors are
%% encouraged to surround collaboration identifiers with ()s. The 
%% \nocollaboration command takes no argument and exists to indicate that
%% the nearby authors are not part of surrounding collaborations.

%% Mark off the abstract in the ``abstract'' environment. 
\begin{abstract}
Gaussian processes are a model of stochastic variability frequently used in analyzing astrophysical time-series. 
They have been used to study variability in light curves of stars and AGN, as well as the spatial 
distribution of the extragalactic dust distribution. In the realm of stellar variability, GP regression 
is used to characterise stellar rotation periods, search for transit signals in noisy data, and analyze 
RV curves. One of the chief limitations of this method is the computational time incurred in computing 
a GP model for large or multi-dimensional data-sets. While approximate methods can make GP regression 
feasible for some of these applications, in others exact methods are preferable. Here 
we present a method based on the \celerite GP implementation which enables fast, exact 
computation of two-dimensional GP models for data-sets with a small second dimension. This includes 
multi-bandpass photometry of transit and microlensing light curves. Our method also may have applications 
to RV and direct imaging methods. 
\end{abstract}

%% Keywords should appear after the \end{abstract} command. 
%% See the online documentation for the full list of available subject
%% keywords and the rules for their use.
%\keywords{}

%% From the front matter, we move on to the body of the paper.
%% Sections are demarcated by \section and \subsection, respectively.
%% Observe the use of the LaTeX \label
%% command after the \subsection to give a symbolic KEY to the
%% subsection for cross-referencing in a \ref command.
%% You can use LaTeX's \ref and \label commands to keep track of
%% cross-references to sections, equations, tables, and figures.
%% That way, if you change the order of any elements, LaTeX will
%% automatically renumber them.
%%
%% We recommend that authors also use the natbib \citep
%% and \citet commands to identify citations.  The citations are
%% tied to the reference list via symbolic KEYs. The KEY corresponds
%% to the KEY in the \bibitem in the reference list below. 
%\tableofcontents
\section{introduction}\label{sec:intro}
    A Gaussian process (GP) is a generalization of a Gaussian distribution to 
    function-space \citep{Rasmussen2006}. GPs have been used extensively in 
    astrophysics as a model of stochastic variability across both space and time, 
    to study a diverse range of phenomena including variable stars, AGN\citep{Kelly2014}, the 
    extragalactic dust distribution\citep{Sale2018}, and gravitational wave signals\citep{Moore2016}. 
    They have also been used to account 
    for correlated noise in photometric and RV measurements of 
    exoplanet hosts\citep{Aigrain2016,Jones2017,Rajpaul2015}. 
    
    GP models offer advantages over other methods of modeling stochastic variability 
    because they are able to account for correlated variations without the imposition 
    of a parametric model. \gordontodo{more about advantages of GPs}
    
    The primary limitation of GP methods is that most GP operations are 
    computationally expensive. For instance, the common tasks 
    of computing likelihoods and sampling from the GP require 
    $\mathcal{O}(N^3)$ operations for $N$ data points. This is 
    especially problematic for use cases which require repeated calls 
    to the likelihood function, such as minimization and performing 
    MCMC. This has prevented the adoption of GP methods for data-sets 
    larger than $N\sim 10^4$ points\citep{Deisenroth2015}. 
    
    The issue of computational expense can be partially overcome either by approximating 
    the GP or by restricting the user to a subset GPs for which the computation 
    can be sped up\citep{Rasmussen2006}. In the latter category we 
    find \celerite\citep{Foreman-Mackey2017}, a fast one-dimensional GP 
    method which increases the speed of most common GP computations to $\mathcal{O}(NJ^2)$ 
    where $J$ is typically small compared to $N$. \celerite achieves this speedup by 
    limiting the user to GPs with a specific functional form of the covariance. 
    Another limitation of \celerite is that the method is only applicable to 
    one-dimensional GPs. Here we present a method to rectify this difficiency of 
    the original \celerite method. Our extension of \celerite computes two-dimenional 
    GPs on an $N$ by $M$ grid in $\mathcal{O}(NJ^2M^3)$ operations. This is an improvement 
    over the general case in which the computation of the same GP would require $\mathcal{O}(N^3M^3)$ 
    operations. Because the speed of our computation is still sharply dependent on $M$, it 
    is most useful in cases where $M << N$. An example would be modeling variability in 
    multi-bandpass photometry where $M$ would represent the number of bands. 

    In this paper we first review the \celerite method before introducing our extension 
    of the original method. We then give a detailed example of GP regression on multi-band 
    transit photometry to recover transit parameters in the presence of significant 
    correlated noise. Finally, we discuss other potential applications to our method and 
    conclude with an outline of future work in which we hope to further reduce the 
    computational expense of a two-dimensional GP. This would enable the use of 
    GP methods on even larger data-sets and potentially make feasible GP computations 
    in higher dimensions. 
		
\section{gaussian processes and the celerite model}
	A Gaussian process is a stochastic noise model which consists of a mean:
	\begin{equation} 
		\bvec{\mu_\theta}(\bvec{x}) = \expandvec{\mu_\bvec{\theta}(x_1)}
		    {\mu_\bvec{\theta}(x_N)}
	\end{equation}
	and covariance defined the kernel function $k_\bvec{\alpha}(x_n, x_m)$. 
	The mean and kernel functions depend on the parameters 
	$\bvec{\theta}$ and $\bvec{\alpha}$ respectively, which are referred to 
	as ``hyperparameters" of the GP. The kernel function defines a covariance matrix 
	$\left[K\right]_{n, m} = k_\alpha(x_n, x_m)$. This model has a likelihood 
	function given by
	\begin{eqnarray}
		\ln\ \mathcal{L(\bvec{\theta}, \bvec{\alpha})} &=& \ln\ 
		    p(\bvec{y}|\bvec{x}, \bvec{\theta}, \bvec{\alpha}) \\ 
		&=& -\frac{1}{2}\bvec{r_\theta}^\T K_\bvec{\alpha}^{-1}\bvec{r_\theta} 
			-\frac{1}{2}\ln\ \mathrm{det}(K_\bvec{\alpha}) - \frac{N}{2}\ln(2\pi) \nonumber
	\end{eqnarray}
	where 
	\begin{equation}
		\bvec{y} = \expandvec{y_1}{y_N}
	\end{equation}
	are the data, $N$ is the number of datapoints, and
	\begin{equation}
		\bvec{r_\theta} = \bvec{y}-\bvec{\mu_\theta}(\bvec{x})
	\end{equation}
	By maximizing the likelihood (or, in practice, minimizing the negative 
	of the log-likelihood), one can obtain an estimate of the hyperparameters 
	$\bvec{\theta}$ and $\bvec{\alpha}$. Markov Chain Monte Carlo (MCMC) methods can be used to 
	sample the posterior distribution over the hyperparameters. 
	\subsection{The \celerite model}
		The primary limitation of Gaussian process noise models is that they 
		are computationally expensive, with computation of the likelihood function 
		scaling as $\mathcal{O}(N^3)$ due to the matrix inversion. This is especially 
		problematic for use cases such as MCMC which require calling the likelihood 
		function many times. This has prevented the adoption of Gaussian process noise models for 
		datasets larger than $N \approx 10^3$, except in cases where approximate 
		methods suffice. The \celerite method overcomes this limitation by reducing 
		the time to execute most GP computations to linear time for one class of 
		kernel functions\citep{Foreman-Mackey2017}. We give a brief description of the \celerite method 
		and its limitations below. 
		
		Consider a one-dimensional gaussian process evaluated at the coordinates
		\begin{equation}
			\bvec{x} = \expandvec{t_1}{t_N}
		\end{equation}
		The \celerite kernel is given by
		\begin{equation}
			k_\alpha(t_n, t_m) = \sigma_n^2 \delta_{nm} + \sum_{j=1}^J a_j e^{-c_j\tau_{nm}}
		\end{equation}
		where $\bvec{\alpha} = (a_1...a_j, c_1...c_j)$, $\sigma_n^2$ is the variance of the gaussian-distributed white noise, and $\tau_{nm} = |t_n-t_m|$. 
		The coefficients $a$ and $c$ may be complex, in which case we introduce $b$ and $d$ which are the imaginary parts of $a$ and $c$ respectively. 
		This kernel defines a \celerite model with $J$ terms. 
		
		For a kernel function of this form, the covariance matrix is a symmetric, semiseparable with semiseparability rank $R=2J$. A matrix of this type can 
		be written in terms of two generator matrices $U$ and $V$, both of size $(N\times 2J)$, and a diagonal matrix $A$:
		\begin{equation}
		\label{eqn:KUV}
			K = A + \mathrm{tril}(UV^\T) + \mathrm{triu}(VU^\T)
		\end{equation}	
		In the case of our covariance matrix, the generator matrices are specified by:	
		\begin{eqnarray}
			U_{n, 2j-1} &=& a_je^{-c_jt_n}\cos(d_jt_n) + b_je^{-c_jt_n}\sin(d_jt_n) \nonumber \\
			U_{n, 2j} &=& a_je^{-c_jt_n}\sin(d_jt_n) - b_je^{-c_jt_n}\cos(d_jt_n) \nonumber \\
			V_{m, 2j-1} &=& e^{c_jt_m}\cos(d_jt_m) \nonumber \\
			V_{m, 2j} &=& e^{c_jt_m}\sin(d_jt_m)
		\end{eqnarray}
		and A is given by:
		\begin{equation}
			A_{n,n} = \sigma_n^2 + \sum_{j=1}^Ja_j
		\end{equation}
		Computing the Cholesky decomposition for this covariance matrix can be accomplished in $\mathcal{O}(NJ^2)$ operations, allowing for the 
		fast computation of the GP likelihood function\footnote{The algorithm is described in appendex \ref{sec:celerite_algorithm}}. 
		
		%\gordontodo{Add discussion of the versatility of this kernel, and it's connection to stochastically driven harmonic oscillators.}
		%
		%\gordontodo{Add discussion of semiseperability --- the reader should understand that the limitation of \celerite is that only kernels of this form can be 
		%represented by a semi-seperable matrix, which is what makes moving to two dimensions slightly more complicated than ordinary.}
		The main limitation of \celerite is that the method only applies to one class of kernels. However, the \celerite kernel overcomes this limitation 
		by being both versatile in its ability to approximate other kernels, and also directly applicable to many problems. The versatility of this 
		kernel is demonstrated in \gordontodo{figure reference} which shows approximations to several popular kernels achieved by appropriate choices 
		of the \celerite coefficients $a_j$ and $c_j$. 
		
		One model of stellar oscillations models the star as a stochastically-driven damped harmonic oscillator\citep{Anderson1990}. The solution to the equations describing 
		such an oscillator is a GP with a \celerite kernel with coefficients 
		\begin{eqnarray}
			a_{j\pm} &=& \frac{1}{2}S_0\omega_0\left[1\pm\frac{1}{\sqrt{1-4Q^2}}\right] \\
			c _{j\pm}&=& \frac{\omega_0}{2Q}\left[1 \mp \sqrt{1-4Q^2}\right]
		\end{eqnarray}
		where $S_0$ is proportional to the power at the un-damped frequency of the oscillator, $\omega_0$, and $Q$ is a parameter known as 
		the quality factor of the oscillator. Variations in the stellar radius due to these oscillations gives rise to brightness variations in the star's 
		light curve \gordontodo{reference?}. 
		This means that a \celerite GP can be used as a model for stellar variability due 
		to p-mode oscillations. Additionally, setting $Q=1/\sqrt{2}$ results in a PSD 
		which has been used to describe granulation-driven stellar variability\citep{Kallinger2014}.

\section{2d gaussian processes}
	In addition to being limited to one class of kernels \celerite, as formulated above, is inherently one-dimensional. For many applications, such 
	as modeling noise in single-bandpass light curves or RV time series GP computations in one dimension are all that is necessary. However in 
	other cases such as modeling noise in simultaneous multi-bandpass light curves or disentangling noise in RV data using multiple activity 
	indicators, two-dimensional GP methods are necessary. We outline a method to compute a GP in two dimensions utilizing the \celerite 
	method for the larger of the two dimensions to speedup most GP operations by a factor of $\sim\mathcal{O}(N^2)$ over ordinary 2D GPs. 
	
	In two-dimensions the independent variable is
	\begin{equation}
		\bvec{x} = \expandvec{(t_1, u_1)}{(t_N, u_N)}
	\end{equation}
	If the covariance between two points satisfies 
	\begin{equation}
	\label{eqn:multiplication_condition}
		k_\alpha(x_n, x_m) = q_\alpha(t_n, t_m)r_\alpha(u_n, u_m)
	\end{equation}
	then the covariance matrix has the structure of a Hadamard matrix product (element-wise 
	multiplication )
	\begin{equation}
		\left[K_\alpha\right]_{nm} = \left[Q_\alpha\right]_{nm}\left[R_\alpha\right]_{nm}
	\end{equation}
	or 
	\begin{equation}
		K = Q\circ R
	\end{equation}
	Now consider a GP evaluated on a $(N\times M)$ grid. We begin by defining
	\begin{eqnarray}
		\bvec{t'} &=& \expandvec{t'_1}{t'_N} \\
		\bvec{u'} &=& \expandvec{u'_1}{u'_M}
	\end{eqnarray}
	to be vectors containing only the unique $t$ and $u$ values in increasing order. 
	%, such that 
	%\begin{equation}
	%	\bvec{x} = \expandvec{((t'_1, u'_1)\cdots(t'_N,u'_1), (t'_1, u'_2)\cdots(t'_N,u'_2)}{(t'_1, u'_M)\cdots(t'_N, u'_M)}
	%\end{equation}
	We also define the corresponding covariance matrices for each dimension: 
	\begin{subequations}
	\label{eqn:QR_defs}
	\begin{eqnarray}
		\left[Q'_\alpha\right]_{nm} &=& q_\alpha(t'_n, t'_m) \\
		\left[R'_\alpha\right]_{pq} &=& r_\alpha(u'_p, u'_q) 
	\end{eqnarray}
	\end{subequations}
	In this case, assuming (\ref{eqn:multiplication_condition}), the full covariance matrix can be written as a Kronecker product between these 
	two one-dimensional covariances\footnote{See appendix \ref{sec:matrix_prod} for a proof of (\ref{eqn:kronecker_K}) and notes on the Hadamard and Kronecker products. }: 
	\begin{equation}
	\label{eqn:kronecker_K}
		K_\alpha = Q'_\alpha \otimes R'_\alpha
	\end{equation}
	Since the rest of this discussion will focus on the case of gridded data, we will drop the prime notation and use $Q_\alpha$ and $R_\alpha$ to refer to the 
	matrices in (\ref{eqn:QR_defs}). In the following discussion we assume that the covariance in $t$ is described by a \celerite kernel, and that 
	the covariance in $u$ is arbitrary. This means that $Q_\alpha$ can be expressed in terms of the generator matrices $U$ and $V$.  Following equation 
	(\ref{eqn:KUV}), in the absence of a white noise term, we can write the covariance matrix as follows\footnote{See appendix \ref{sec:Kproof} for proof}:
	\begin{eqnarray}
	\label{eqn:KUVR}
		%\nonumber K &=& A\otimes R + \mathrm{tril}(UV^\T)\otimes R + \mathrm{triu}(VU^\T)\otimes R \\
		%\nonumber &=& A\otimes R + \mathrm{tril}((UV^\T)\otimes (RI_M)) + \mathrm{triu}((VU^\T)\otimes (RI_M) ) \eqnum{\value{equation}} \\
		\nonumber K &=& \left(A + \mathrm{tril}(UV^\T) + \mathrm{triu}(VU^\T)\right)\otimes R \\
		&=& A' + \mathrm{tril}(U'V'^\T) + \mathrm{triu}(V'U'^T)
	\end{eqnarray}
	where
	\begin{eqnarray}
		A' &=& A\otimes R \\
		U' &=& U\otimes R \\
		V' &=& V\otimes I_M
	\end{eqnarray}
	To include white noise we add a white noise term to each element of A:
	\begin{equation}
		A'_{n, n} \to A'_{n, n} + \sigma_n^2
	\end{equation}
	From the form of equation \ref{eqn:KUVR} we can see that the covariance is, as before, semiseparable. However Kronecker 
	multiplication by $R$ and $I_M$ has increased the size of the generator matrices from $(N\times 2J)$ to $(NM\times 2JM)$. As a result,  
	the number of operations necessary to compute the Cholesky decomposition to increase from $\mathcal{O}(NJ^2)$ to $\mathcal{O}(NJ^2M^3)$. 
	The number of operations for sampling from and extrapolating/interpolating with the two-dimensional GP scales the same. Some improvement 
	can be made in the scaling for extrapolation and interpolation if the covariance in the second dimension can be expressed via 
	a \celerite kernel. In this case the algorithm requires $\mathcal{O}(nNP + mMP)$ operations where $P$ is the number of points at which the prediction is evaluated and $n, m$ are constants. The 
	Cholesky composition algorithm as well as algorithms for interpolation/extrapolation and sampling from the GP are described in appendix 
	\ref{sec:algorithms}. 
	
	It should be noted that the scaling of our method is still relatively poor as we add points to our grid in the second dimension. This 
	is why the method is most suitable for cases where the second dimension is much smaller than the first, i.e. where $M << N$. 
	This condition applies to the important cases of modeling noise in multi-bandpass observations. 
	%Into appendix? 
	%So that $Q'_\alpha$ is a symmetric $(N\times N)$ matrix (with hyperparameters $\alpha$) 
	%describing the covariance for a one-dimensional GP evaluated along $\bvec{t}$ and 
	%$R'_\alpha$ is the same for $\bvec{u}$.  These matrices can be related back to the un-primed $Q_\alpha$ and $R_\alpha$ 
	%matrices via the Kronecker product. 
	
	%\subsection{kronecker structure of the 2d covariance matrix}
	%In two dimensions the kernel function depends on two coordinates. We will continue to use
	%\begin{equation}
	%	\bvec{t} = \expandvec{t_1}{t_N}
	%\end{equation}
	%to refer to the first coordinate, and introduce
	%\begin{equation}
	%	\bvec{u} = \expandvec{u_1}{u_M}
	%\end{equation}
	%to refer to the second coordinate. In most cases, we will demand that $M << N$. We then define $\bvec{x}$ to be the list of points
	%\begin{equation}
	%	\bvec{x} = \expandvec{(t_1, u_1), (t_1, u_2), \cdots (t_1, u_M)}{(t_N, u_M)}
	%\end{equation}
	%We can also write this as
	%\begin{equation}
	%	x_i = (t_{\lfloor(i-1)/M\rfloor + 1}, u_{i - \lfloor(i-1)/M\rfloor M})
	%\end{equation} 
	%The covariance between $x_i$ and $x_j$ is then given by
	%\begin{equation}
	%	k_{\bvec{\alpha}\bvec{\beta}}(x_i, x_j) = \sigma_i^2\delta_{ij} + q_\bvec{\alpha}(\tau_{ij})\circ r_\bvec{\beta}(\nu_{ij})
	%\end{equation}
	%where $\tau_{ij} = |t_{\lfloor(i-1)/M\rfloor + 1}-t_{\lfloor(j-1)/M\rfloor + 1}|$, 
	%$\nu_{ij} = |u_{i - \lfloor(i-1)/M\rfloor M}-u_{j - \lfloor(j-1)/M\rfloor M}|$; 
	%$q$ and $r$ are one-dimensional kernel functions which depend on the hyperparameters $\bvec{\alpha}$ and 
	%$\bvec{\beta}$ respectively; 
	%and $\circ$ is some binary operation. 
	%If $Q_\bvec{\alpha}$ and $R_\bvec{\alpha}$ are the covariance matrices corresponding to 
	%$q_\bvec{\alpha}$ and $r_\bvec{\alpha}$ such that
	%\begin{equation}
	%	\left[Q_\bvec{\alpha}\right]_{ij} = q_\bvec{\alpha}(\tau_{ij})\ \ \ \mathrm{and}\ \ \ \left[R_\bvec{\beta}\right]_{ij} = r_\bvec{\beta}(\tau_{ij})
	%\end{equation} 
	%then, using $q_{ij}$ and $r_{ij}$ as shorthand for the entries in $Q_\bvec{\alpha}$ and $R_\bvec{\beta}$, $K_\bvec{\alpha\beta}$ can be represented as: 
	%\begin{equation}
	%	K_\bvec{\alpha\beta} = \Sigma + 
	%		\begin{bmatrix}
	%			q_{11}\circ R_\bvec{\beta} & ... & q_{1N}\circ R_\bvec{\beta} \\
	%			\vdots & \ddots & \\
	%			q_{N1}\circ R_\bvec{\beta} & ... & q_{NN}\circ R_\bvec{\beta}
	%		\end{bmatrix}
	%\end{equation}
	%where $[\Sigma]_{ij} = \sigma_i^2\delta_{ij}$ and
	%\begin{equation}
	%	q_{pq}\circ R_\bvec{\alpha} = 
	%		\begin{bmatrix}
	%			q_{pq}\circ r_{11} & ... & q_{pq}\circ r_{1M} \\
	%			\vdots & \ddots & \\
	%			q_{pq}\circ r_{M1} & ... & q_{pq}\circ r_{MM}
	%		\end{bmatrix}
	%\end{equation}
	%If the operator $\circ$ represents multiplication, we have 
	%\begin{equation}
	%	K_\bvec{\alpha\beta} = \Sigma + Q_\bvec{\alpha} \otimes  R_\bvec{\beta}
	%\end{equation}
	%where $\otimes$ is the Kronecker product. If the covariance in $\bvec{t}$ is described by a \celerite kernel can write 
	%\begin{eqnarray}
	%	K &=& \Sigma + \left[\mathrm{tril}(UV^\T) + \mathrm{triu}(VU^\T)\right]\otimes R \\
	%	&=& \Sigma + \mathrm{tril}\left[ (U\otimes R)(V\otimes I_M)^\T\right] + \mathrm{triu}\left[ (V\otimes I_M)(U\otimes R)^\T\right]
	%\end{eqnarray}
	%This covariance has the same semi-separable form as in the one-dimensional case, but now $K$ is an $(NM\times NM)$ matrix of rank $2JM$. 
	%This means that we can apply the same Cholesky decomposition algorithm (described in the appendix) as in the 1d case to compute the GP in 
	%$\mathcal{O}(NJ^2M^3)$. While our implementation only handles the Kronecker product case, 
	%his result holds in the case that $\circ$ is an operation other than multiplication, so long as $\circ$ has the property
	%\begin{equation}
	%	(a\circ B)(c\circ D) = (ac)\circ(BD)
	%\end{equation}
	%for scalars $a$ and $b$ and matrices $B$ and $D$. 
	%where $a\circ B$ is the matrix 
	%\begin{equation}
	%	a\circ B = \begin{bmatrix}
	%		a\circ b_{11} & a\circ b_{12} & \cdots \\
	%		a\circ b_{21} &  a\circ b_{22} & \\
	%		\vdots & & \ddots & 
	%	\end{bmatrix}
	%\end{equation}
	%\gordontodo{See appendix for proof}
	
	%\subsection{sampling the distribution}
	%A gaussian process can be used to simulate correlated noise. If $L$ is the lower triangular factor from the Cholesky decomposition of the 
	%$(N\times N)$ covariance matrix $K$, and $\bvec{z}$ is a vector of length $N$ containing random numbers drawn for a standard normal distribution, i.e.
	%\begin{equation}
	%	\bvec{z} \sim \mathcal{N}(1, 0)
	%\end{equation}
	%then $\bvec{x} = \bvec{\mu_\bvec{\theta}(\bvec{x})} + L\bvec{z}$ is a vector with entries correlated by $K$ and with mean $\bvec{\mu_\theta}$, i.e.
	%\begin{equation}
	%	\bvec{x} \sim \mathcal{N}(\bvec{\mu_\theta}, K)
	%\end{equation}
	%\gordontodo{fix this so that $\mu$ depends on $\theta$ and is a function of $\bvec{t}$ or something like that. Compuational cost should be $\mathcal{O}(NJM^2)$}
	%
	%\subsection{interpolation and extrapolation}	
	%\gordontodo{Bit more complicated --- if both dimensions are celerite processes then the scaling is better than in the case where $R$ is not celerite. You have notes on this.}
	
%\section{example: exomoons}
%	\gordontodo{What if I used Kepler-1625 as an example? Could simulate WFC3 GRISM data and show that moon could be validated with Celerite2D?}
%	Gaussian process noise models are most advantageous when correlated noise dominates over white noise. 
%	This is already the case for state-of-the-art radial velocity observations, and transit 
%	photometry is not far behind. Future space-based observatories such as James Webb 
%	will enable high-precision photometry in which stellar variability is the main barrier to detecting ever more shallow transit signals. 
%	Stellar variability which obscures transit signal can be a result of spot and faculae crossings, asteroseismic oscillations, or variable 
%	granulation on the star's surface. 
	
%	\gordontodo{Are GPs applicable to instrumental noise as well? Seems best to account for instrumental effects with models that account for known factors since 
%	they might not be well-described by a gaussian process, right?}
	
%	\gordontodo{What about other methods of accounting for astrophysical noise? i.e. cosine filtering, polynomials, etc. --- also related to GP as non-parametric 
%	noise model}
\section{example: solar system transits}
    One application of fast two-dimensional Gaussian Processes is modeling noise in multi-bandpass light 
    curves to, for example, search for transits and infer their parameters. One-dimensional GPs are already in use as 
    noise models for transit light curves. By setting the mean of the GP equal to a transit model and minimizing the GP likelihood, 
    transit parameters can be more accurately inferred in the presence of correlated stellar noise. However, for cases where a shallow 
    transit signal is obscured by correlated noise, a one-dimensional GP noise model is not sufficient to disentangle signal from noise. 
    
    This problem can be mitigated by examining the wavelength-dependence of the star's variability. The correlated noise component 
    of the light curve will be subject to this wavelength-dependence whereas the mean (the transit signal) will not share the same 
    dependence. Thus by including multiple bandpasses and simultaneously modeling the covariance between bands using a two-dimensional 
    GP. 
    
    In what follows we aim to demonstrate this method using transits of Solar System planets as an example. We use publicly available 
    light curves from the SOHO mission's three-channel sunphotometer (SPH) \citep{Frohlich1995, Frohlich1997, Jimenez2002} and add Gaussian noise to simulate observations 
    taken at varying distances from the Sun. We've injected transits of the Earth and Venus into that data and we demonstrate 
    the recovery of transit parameters for both objects. 
    \subsection{modeling the wavelength-dependence of stellar variability}
        Our first task is to construct a model of the Sun's variability that allows us to determine the form of the $R$ matrix. The sun's p-mode oscillations peak at between 5 and 6 minutes \citep{Kiefer2018} compared to transit durations for Venus and Earth 
        of 11 and 13 hours respectively, so we ignore this source of variability in our model. Of more relevance are brightness variations modulated by changing patterns of 
        hotter and cooler regions of the photosphere. We model the solar photosphere as 
        a mix of two regions of temperatures $T_h$ and $T_c$ with $T_h > T_c$. The flux 
        in a filter $A$ is 
        \begin{equation}
            F_A = \int_{\lambda_1}^{\lambda_2}\phi_A(\lambda)\left[xI_\lambda(T_h)+(1-x)I_\lambda(T_c)\right]d\lambda
        \end{equation}
        where $\phi_A(\lambda)$ is the profile of the filter and $x$ is the covering fraction of the region at $T_h$.
        As the covering fraction varies, the flux changes according to
        \begin{equation}
            \frac{dF_A}{dx} = \int_{\lambda_1}^{\lambda_2}\phi_A(\lambda)\left[I_\lambda(T_h)-I_\lambda(T_c)\right]d\lambda
        \end{equation}
        From this we see that the rate at which the flux varies with variations in $x$ depends on the 
        contrast in brightness between the two regions within the filter. We therefore expect the flux 
        to be more variable where the contrast between the two regions is higher than where it is lower. For 
        instance, in the infrared, we should see higher amplitude variability features in filters 
        centered at shorter wavelengths than longer ones. 
        
        We can expand the flux as a function of covering 
        fraction in a Taylor series to first order: 
        \begin{equation}
            F_A(x) = F_A(\bar{x}) + \frac{dF_A}{dx}(x-\bar{x})
        \end{equation}
        %Putting this in terms of the deviation of the flux from $x=x_0$ we have
        %\begin{equation}
        %    \delta F_A = F_A(x)-F_A(x_0) = \frac{dF_A}{dx}(x-x_0)
        %\end{equation}
        where $\bar{x}$ is the mean covering fraction. We can then compute the covariance between the flux in filter $A$ at time $t_n$ and the flux in some filter $B$ at time $t_m$/ 
        Filter $B$ is assumed to be centered at a longer wavelength than $A$:
        \begin{eqnarray}
            \nonumber \mathrm{cov}(F_A(t_n), F_B(t_m)) &=& \mathrm{E}\left[(F_A(t_n) - \bar{F_A})(F_B(t_m)-\bar{F_B})\right] \\
            \nonumber &=& \frac{dF_A}{dx}\frac{dF_B}{dx}\mathrm{E}\left[(x_n-\bar{x})(x_m-\bar{x})\right] \\
            &=& C_AC_B\mathrm{cov}(x_n, x_m)
        \end{eqnarray}
        where $C_A$ and $C_B$ are the derivatives of $F_A$ and $F_B$ with respect to 
        covering fraction and we've used the fact that $\mathrm{cov}(x_n, x_m) = \mathrm{E}\left[(x_n-\bar{x})(x_m-\bar{x})\right]$. 
        This result satisfies equation (\ref{eqn:multiplication_condition}) with $r(u_n, u_m) = C_nC_m$. The 
        corresponding covariance matrix for the second dimension is 
        \begin{equation}
            [R]_{nm} = C_nC_m
        \end{equation}
    \subsection{Inferring transit parameters}
        

\section{discussion}
	\subsection{other applications}

\section{conclusion}

%% If you wish to include an acknowledgments section in your paper,
%% separate it off from the body of the text using the \acknowledgments
%% command.
\acknowledgments

%% To help institutions obtain information on the effectiveness of their 
%% telescopes the AAS Journals has created a group of keywords for telescope 
%% facilities.
%
%% Following the acknowledgments section, use the following syntax and the
%% \facility{} or \facilities{} macros to list the keywords of facilities used 
%% in the research for the paper.  Each keyword is check against the master 
%% list during copy editing.  Individual instruments can be provided in 
%% parentheses, after the keyword, but they are not verified.

%\vspace{5mm}
%\facilities{}

%% Similar to \facility{}, there is the optional \software command to allow 
%% authors a place to specify which programs were used during the creation of 
%% the manusscript. Authors should list each code and include either a
%% citation or url to the code inside ()s when available.

%\software{}

%% Appendix material should be preceded with a single \appendix command.
%% There should be a \section command for each appendix. Mark appendix
%% subsections with the same markup you use in the main body of the paper.

%% Each Appendix (indicated with \section) will be lettered A, B, C, etc.
%% The equation counter will reset when it encounters the \appendix
%% command and will number appendix equations (A1), (A2), etc. The
%% Figure and Table counter will not reset.

\appendix
\section{The \celerite Algorithm}
\label{sec:celerite_algorithm}
\section{The Hadamard and Kronecker Products}
\label{sec:matrix_prod}
\section{Proof of \ref{eqn:KUVR}}
\label{sec:Kproof}
\section{Computing the Two-dimensional GP}
\label{sec:algorithms}

%% The reference list follows the main body and any appendices.
%% Use LaTeX's thebibliography environment to mark up your reference list.
%% Note \begin{thebibliography} is followed by an empty set of
%% curly braces.  If you forget this, LaTeX will generate the error
%% "Perhaps a missing \item?".
%%
%% thebibliography produces citations in the text using \bibitem-\cite
%% cross-referencing. Each reference is preceded by a
%% \bibitem command that defines in curly braces the KEY that corresponds
%% to the KEY in the \cite commands (see the first section above).
%% Make sure that you provide a unique KEY for every \bibitem or else the
%% paper will not LaTeX. The square brackets should contain
%% the citation text that LaTeX will insert in
%% place of the \cite commands.

%% We have used macros to produce journal name abbreviations.
%% \aastex provides a number of these for the more frequently-cited journals.
%% See the Author Guide for a list of them.

%% Note that the style of the \bibitem labels (in []) is slightly
%% different from previous examples.  The natbib system solves a host
%% of citation expression problems, but it is necessary to clearly
%% delimit the year from the author name used in the citation.
%% See the natbib documentation for more details and options.

%\begin{thebibliography}{celerite2d.bib}

% \bibitem[Astropy Collaboration et al.(2013)]{2013A&A...558A..33A} Astropy Collaboration, Robitaille, T.~P., Tollerud, E.~J., et al.\ 2013, \aap, 558, A33 

%\end{thebibliography}
\bibliography{main.bib}

%% This command is needed to show the entire author+affilation list when
%% the collaboration and author truncation commands are used.  It has to
%% go at the end of the manuscript.
%\allauthors

%% Include this line if you are using the \added, \replaced, \deleted
%% commands to see a summary list of all changes at the end of the article.
%\listofchanges

\end{document}

% End of file `sample62.tex'.


